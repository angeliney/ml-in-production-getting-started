{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup dataset for experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/angeline/miniconda3/envs/mlops-training/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import lancedb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make different audio queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "import random\n",
    "\n",
    "def load_and_process_audio_files(file_range=(1, 11), chunk_size=44100 * 10,\n",
    "                                 add_offset=False, pitch_shift=False, time_stretch=False):\n",
    "    # List to hold dictionaries with chunked audio data\n",
    "    sound_arrays = []\n",
    "\n",
    "    # Process each file\n",
    "    for num in range(file_range[0], file_range[1]):\n",
    "        for letter in [\"a\", \"b\"]:\n",
    "            # Load the audio file\n",
    "            data, sample_rate = sf.read(f\"../../data/CSD/english/wav/en{num:03}{letter}.wav\")\n",
    "            data = np.array(data)\n",
    "            \n",
    "            # Combine stereo channels into mono\n",
    "            if np.ndim(data) == 2:\n",
    "                data = np.mean(data, axis=1)\n",
    "            \n",
    "            # Calculate the total number of chunks based on the original chunk size\n",
    "            num_chunks = len(data) // chunk_size\n",
    "\n",
    "            for i in range(num_chunks):\n",
    "                # Apply random offset to start chunking at a slightly different point\n",
    "                if add_offset:\n",
    "                    offset = random.randint(-int(chunk_size * 0.2), int(chunk_size * 0.2))\n",
    "                else:\n",
    "                    offset = 0\n",
    "                start = max(0, i * chunk_size + offset)\n",
    "                end = min(len(data), start + chunk_size)\n",
    "                chunk = data[start:end]\n",
    "                \n",
    "                # Randomly decide to apply pitch shifting and time stretching\n",
    "                pitch_shift = random.choice([-2, -1, 0, 1, 2]) if pitch_shift else 0  # Random pitch shift between -2 and 2 semitones\n",
    "                stretch_factor = random.uniform(0.8, 1.2)  if time_stretch else 1.0 # Random stretch factor between 0.8 and 1.2\n",
    "\n",
    "                # Apply pitch shifting if not zero\n",
    "                if pitch_shift != 0:\n",
    "                    chunk = librosa.effects.pitch_shift(chunk, sr=sample_rate, n_steps=pitch_shift)\n",
    "\n",
    "                # Apply time stretching if not 1.0\n",
    "                if stretch_factor != 1.0:\n",
    "                    chunk = librosa.effects.time_stretch(chunk, rate=stretch_factor)\n",
    "\n",
    "                chunk = chunk[:chunk_size]\n",
    "                if len(chunk) < chunk_size:\n",
    "                    chunk = np.pad(chunk, (0, chunk_size - len(chunk)), mode=\"constant\")\n",
    "                # Append the processed chunk to the list\n",
    "                sound_arrays.append({\n",
    "                    \"vector\": chunk,\n",
    "                    \"sample_rate\": sample_rate,\n",
    "                    \"pitch_shift\": pitch_shift,\n",
    "                    \"time_stretch\": stretch_factor,\n",
    "                    \"offset\": offset,\n",
    "                    \"chunk_num\": i+1,\n",
    "                    \"song_num\": num,\n",
    "                    \"song_version\": letter,\n",
    "                    \"filename\": f\"en{num:03}{letter}_chunk{i+1}_offset{offset}_ps{pitch_shift}_ts{stretch_factor:.2f}\"\n",
    "                })\n",
    "\n",
    "    return sound_arrays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = \"../../data/lancedb-data/audio-lancedb\"\n",
    "db = lancedb.connect(uri)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(False, False, False)\n",
      "Processing files 1 to 11\n",
      "Processing files 11 to 21\n",
      "Processing files 21 to 31\n",
      "Processing files 31 to 41\n",
      "Processing files 41 to 51\n",
      "(True, False, False)\n",
      "Processing files 1 to 11\n",
      "Processing files 11 to 21\n",
      "Processing files 21 to 31\n",
      "Processing files 31 to 41\n",
      "Processing files 41 to 51\n",
      "(False, True, False)\n",
      "Processing files 1 to 11\n",
      "Processing files 11 to 21\n",
      "Processing files 21 to 31\n",
      "Processing files 31 to 41\n",
      "Processing files 41 to 51\n",
      "(False, False, True)\n",
      "Processing files 1 to 11\n",
      "Processing files 11 to 21\n",
      "Processing files 21 to 31\n",
      "Processing files 31 to 41\n",
      "Processing files 41 to 51\n",
      "(False, True, True)\n",
      "Processing files 1 to 11\n",
      "Processing files 11 to 21\n",
      "Processing files 21 to 31\n",
      "Processing files 31 to 41\n",
      "Processing files 41 to 51\n",
      "(True, True, True)\n",
      "Processing files 1 to 11\n",
      "Processing files 11 to 21\n",
      "Processing files 21 to 31\n",
      "Processing files 31 to 41\n",
      "Processing files 41 to 51\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "settings = [\n",
    "    (False, False, False),\n",
    "    (True, False, False),\n",
    "    (False, True, False),\n",
    "    (False, False, True),\n",
    "    (False, True, True),\n",
    "    (True, True, True)\n",
    "]\n",
    "db_setup = False\n",
    "\n",
    "for setting in settings:\n",
    "    print(setting)\n",
    "    add_offset, pitch_shift, time_stretch = setting\n",
    "    for i in range(1, 51, 10):\n",
    "        print(f\"Processing files {i} to {i+10}\")\n",
    "        sound_arrays = load_and_process_audio_files(file_range=(i, i+10), chunk_size=44100 * 10,\n",
    "                                    add_offset=add_offset, pitch_shift=pitch_shift, time_stretch=time_stretch)\n",
    "\n",
    "        if db_setup:\n",
    "            tbl.add(sound_arrays)\n",
    "        else:\n",
    "            tbl = db.create_table(\"audio_example_queries\", data=sound_arrays)\n",
    "            db_setup = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing files 1 to 11\n",
      "Processing files 11 to 21\n",
      "Processing files 21 to 31\n",
      "Processing files 31 to 41\n",
      "Processing files 41 to 51\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "db_setup = False\n",
    "\n",
    "add_offset, pitch_shift, time_stretch = False, False, False\n",
    "for i in range(1, 51, 10):\n",
    "    print(f\"Processing files {i} to {i+10}\")\n",
    "    sound_arrays = load_and_process_audio_files(file_range=(i, i+10), chunk_size=44100 * 10,\n",
    "                                add_offset=add_offset, pitch_shift=pitch_shift, time_stretch=time_stretch)\n",
    "\n",
    "    if db_setup:\n",
    "        tbl.add(sound_arrays)\n",
    "    else:\n",
    "        tbl = db.create_table(\"audio_dataset\", data=sound_arrays)\n",
    "        db_setup = True\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops-training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
